import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_selection import SelectFromModel
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor

# Load the training data
train_data = pd.read_csv('/content/sample_data/train.csv')

# Extract features and target variable from the training data
X_train = train_data.drop(['id', 'yield'], axis=1)
y_train = train_data['yield']

# Split the data into training and validation sets
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Preprocessing pipeline
preprocessing_pipeline = make_pipeline(StandardScaler())

# Apply preprocessing to training and validation data
X_train_preprocessed = preprocessing_pipeline.fit_transform(X_train)
X_val_preprocessed = preprocessing_pipeline.transform(X_val)

# Feature selection using Random Forest
rf = RandomForestRegressor(n_estimators=100, random_state=42)
rf.fit(X_train_preprocessed, y_train)

# Define the threshold for feature selection
threshold = 0.1

# Feature importance analysis
feature_importances = pd.DataFrame({'Feature': X_train.columns, 'Importance': rf.feature_importances_})
selected_features = feature_importances[feature_importances['Importance'] >= threshold]['Feature']

# Select features from training and validation data
X_train_selected = X_train[selected_features]
X_val_selected = X_val[selected_features]

# Hyperparameter tuning with GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [5, 10, 15],
    'min_samples_leaf': [1, 2, 3]
}

rf_tuned = RandomForestRegressor(random_state=42)
# Perform grid search
grid_search = GridSearchCV(rf_tuned, param_grid, cv=5)
grid_search.fit(X_train_selected, y_train)

# Retrieve the best parameters
best_params = grid_search.best_params_

# Load the test data
test_data = pd.read_csv('/content/sample_data/test.csv')

# Apply preprocessing to test data
X_test_preprocessed = preprocessing_pipeline.transform(test_data.drop('id', axis=1))

# Select features from test data
X_test_selected = test_data[selected_features]

# Create a random forest regressor with the best parameters
final_model = RandomForestRegressor(**best_params, random_state=42)

# Train the final model on the selected features
final_model.fit(X_train_selected, y_train)

# Make predictions on the test data
y_pred_test = final_model.predict(X_test_selected)

# Create a submission DataFrame with the predicted yield values and the corresponding IDs
submission_data = pd.DataFrame({'id': test_data['id'], 'yield': y_pred_test})

# Save the submission DataFrame to a CSV file
submission_data.to_csv('submission.csv', index=False)
